{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Sentiment Analysis â€” Amazon Product Reviews\
",
    "### Step-by-Step Project Insight & Documentation\
",
    "\
",
    "This notebook provides a comprehensive walkthrough of the Sentiment Analysis project, covering data loading, preprocessing, feature extraction, model training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation\
",
    "We start by importing necessary libraries and loading the dataset. We use a subset of Amazon Product Reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\
",
    "import numpy as np\
",
    "import matplotlib.pyplot as plt\
",
    "import seaborn as sns\
",
    "from sklearn.model_selection import train_test_split\
",
    "from sklearn.feature_extraction.text import TfidfVectorizer\
",
    "from sklearn.linear_model import LogisticRegression\
",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\
",
    "import nltk\
",
    "from nltk.corpus import stopwords\
",
    "import string\
",
    "\
",
    "nltk.download('stopwords')\
",
    "stop_words = set(stopwords.words('english'))\
",
    "\
",
    "# Sample Data Creation for demonstration\
",
    "data = {\
",
    "    'reviewText': [\
",
    "        'I love this product, it is amazing!',\
",
    "        'Terrible quality, broke in two days.',\
",
    "        'It is okay, does the job but could be better.',\
",
    "        'Excellent purchase, highly recommend.',\
",
    "        'Worst experience ever, very disappointed.',\
",
    "        'Good value for money.',\
",
    "        'Not what I expected, very poor.',\
",
    "        'Fantastic quality and fast shipping.',\
",
    "        'Poor customer service and bad product.',\
",
    "        'Decent product, satisfied with the purchase.'\
",
    "    ],\
",
    "    'sentiment': [1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\
",
    "}\
",
    "df = pd.DataFrame(data)\
",
    "print(\\\"Dataset Head:\\\")\
",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome:** A sample dataset with review text and binary sentiment labels (1 for Positive, 0 for Negative) is initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\
",
    "Preprocessing is crucial in NLP. We remove punctuation and stopwords to focus on the meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\
",
    "    text = text.lower()\
",
    "    text = ''.join([char for char in text if char not in string.punctuation])\
",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\
",
    "    return text\
",
    "\
",
    "df['cleaned_review'] = df['reviewText'].apply(preprocess_text)\
",
    "print(\\\"Cleaned Reviews:\\\")\
",
    "print(df[['reviewText', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** Removing noisy characters and common words reduces the feature space and improves model focus on sentiment-bearing tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction (TF-IDF)\
",
    "We convert the text into numerical vectors using TF-IDF (Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\
",
    "X = tfidf.fit_transform(df['cleaned_review'])\
",
    "y = df['sentiment']\
",
    "\
",
    "print(f\\\"TF-IDF Matrix Shape: {X.shape}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome:** The text data is transformed into a high-dimensional sparse matrix ready for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation\
",
    "We use Logistic Regression as a baseline model for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\
",
    "\
",
    "model = LogisticRegression()\
",
    "model.fit(X_train, y_train)\
",
    "\
",
    "y_pred = model.predict(X_test)\
",
    "print(\\\"Accuracy Score:\\\", accuracy_score(y_test, y_pred))\
",
    "print(\\\"\\\
Classification Report:\\\
\\\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Outcomes\
",
    "Visualizing the confusion matrix helps understand model performance across different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\
",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\
",
    "plt.xlabel('Predicted')\
",
    "plt.ylabel('Actual')\
",
    "plt.title('Confusion Matrix')\
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Insights:**\
",
    "- The model effectively distinguishes between positive and negative reviews even on a small sample.\
",
    "- Further improvements could include using pre-trained embeddings (like Word2Vec or BERT) for better semantic understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
